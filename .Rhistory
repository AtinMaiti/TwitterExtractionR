install.packages("ROAuth")
install.packages("twitteR")
library("RCurl", lib.loc="~/R/win-library/3.4")
library("ROAuth", lib.loc="~/R/win-library/3.4")
library("twitteR", lib.loc="~/R/win-library/3.4")
detach("package:bitops", unload=TRUE)
library("bitops", lib.loc="~/R/win-library/3.4")
library("twitteR")
key = "Q7Lxxxxxxxxx"
secret = "4gLxxxxxxxxxx"
key = "22LdoMzzR7KJgp2LxWH6XDrfT"
secret = "ZpKjG6xHMTgGPHLJpx9kunYl3ZgBpUUUJ7HRpE90BNU7JJ74Jr"
setwd("C:/xxxxxxxx")
setwd("C:\Users\maiti\Desktop\TwitterExtractionR")
setwd("C:/Users/maiti/Desktop/TwitterExtractionR")
download.file(url="http://curl.haxx.se/ca/cacert.pem",
destfile="C:/Users/maiti/Desktop/TwitterExtractionR/cacert.pem",
method="auto")
authenticate <-  OAuthFactory$new(consumerKey=key,
consumerSecret=secret,
requestURL='https://api.twitter.com/oauth/request_token',
accessURL='https://api.twitter.com/oauth/access_token',
authURL='https://api.twitter.com/oauth/authorize')
authenticate$handshake(cainfo="C:/xxxxxxx/cacert.pem")
authenticate$handshake(cainfo="C:/Users/maiti/Desktop/TwitterExtractionR/cacert.pem")
save(authenticate, file="twitter authentication.Rdata")
registerTwitterOAuth(authenticate)
library("twitteR")
userTimeline("Udemy", cainfo="cacert.pem")
save(authenticate, file="twitter authentication.Rdata")
registerTwitterOAuth(authenticate)
?setup_twitter_oauth
setup_twitter_oauth((authenticate)
?setup_twitter_oauth
# Lets start with the Twitter scraping
library("twitteR")
# we need to specify the cainfo to avoid a SSL cert error - this is for Windows machines
# Lets check the latest tweets of Udemy
userTimeline("Udemy", cainfo="cacert.pem")
# searchTwitter is the main function of the package
?searchTwitter
# arguments: since and until are for time specifications
# lang: for languge specification
# geocode: for location specification
# we are now scraping 1k tweekts for Udemy, and we als specify our certificate
udemytweets = searchTwitter("#Udemy", n=1000, cainfo="cacert.pem")
# as you can see, scraping that data is quite time consuming - your machine limits the
# the efficiency and speed of your mining
# if you are plan to scrape a lot in the future 64bit systems and high RAM is desireable
class(udemytweets)
length(udemytweets)
head(udemytweets)
library("tm")
udemylist <- sapply(udemytweets, function(x) x$getText()) # initiating a function
# in depth info about the apply family and functions in the course "R Level 1"
udemycorpus <- Corpus(VectorSource(udemylist)) # use the corpus function
# a corpus is the text body consisting of all the text including the meta info
udemycorpus <- tm_map(udemycorpus, tolower) # putting text to lower case
udemycorpus <- tm_map(udemycorpus, removePunctuation) # remove punct.
udemycorpus <- tm_map(udemycorpus,
function(x)removeWords(x,stopwords())) # remove stopwords (meaningless words)
# there is a link to a stop word list in the link lecture
# Lets see which other transformations tm offers
?getTransformations
# to trasform to plain text which wordcloud can use
udemycorpus <- tm_map(udemycorpus, PlainTextDocument)
library("wordcloud")
? wordcloud
wordcloud(udemycorpus, min.freq=4, scale=c(5,1),
random.color=F, max.word=45, random.order=F)
# changing to a tdm
udemytdm <- TermDocumentMatrix(udemycorpus)
# a DocumentTermMatrix is a very useful tool when it comes to text mining
# it structures the text in a matrix where each term is organized in a column
# each row is a document and the number represents the counts of that term
udemytdm
# frequent terms
findFreqTerms(udemytdm, lowfreq=11)
?findFreqTerms
# associations
findAssocs(udemytdm, 'android', 0.60)
# Lets get a dendrogram to see related terms
# Remove sparse (infrequently used) terms from the term-document matrix
udemy2tdm <-removeSparseTerms(udemytdm, sparse=0.9)
# Lets scale the data
udemy2tdmscale <- scale(udemy2tdm)
# distance matrix
udemydist <- dist(udemy2tdmscale, method = "euclidean")
# hierarchical clustering
udemyfit <- hclust(udemydist)
# Visualize the result
plot(udemyfit)
# to calculate a certain number of groups
cutree(udemyfit, k=6)
# we can even color the 6 groups and plot them
rect.hclust(udemyfit, k=6, border="red")
authenticate$handshake(cainfo="C:/Users/maiti/Desktop/TwitterExtractionR/cacert.pem")
consumerSecret=secret,
requestURL='https://api.twitter.com/oauth/request_token',
accessURL='https://api.twitter.com/oauth/access_token',
authURL='https://api.twitter.com/oauth/authorize')
library("twitteR")
key = "22LdoMzzR7KJgp2LxWH6XDrfT"
secret = "ZpKjG6xHMTgGPHLJpx9kunYl3ZgBpUUUJ7HRpE90BNU7JJ74Jr"
setwd("C:/Users/maiti/Desktop/TwitterExtractionR")
download.file(url="http://curl.haxx.se/ca/cacert.pem",
destfile="C:/Users/maiti/Desktop/TwitterExtractionR/cacert.pem",
method="auto")
authenticate <-  OAuthFactory$new(consumerKey=key,
consumerSecret=secret,
requestURL='https://api.twitter.com/oauth/request_token',
accessURL='https://api.twitter.com/oauth/access_token',
authURL='https://api.twitter.com/oauth/authorize')
authenticate$handshake(cainfo="C:/Users/maiti/Desktop/TwitterExtractionR/cacert.pem")
save(authenticate, file="twitter authentication.Rdata")
registerTwitterOAuth(authenticate)
library("twitteR")
?setup_twitter_oauth
key <- "22LdoMzzR7KJgp2LxWH6XDrfT"
secret <- "ZpKjG6xHMTgGPHLJpx9kunYl3ZgBpUUUJ7HRpE90BNU7JJ74Jr"
secrettk <- "elOR73TOXomTlvMavThhrAv6J7mmc71JbyhPHub99HzG3"
mytoken <- 	"861271732480618496-rJgG5TrInVICmluO8iJNuakqa96wLI7"
?setup_twitter_oauth
setup_twitter_oauth(key, secret, mytoken, secrettk)
key <- "22LdoMzzR7KJgp2LxWH6XDrfT"
secret <- "ZpKjG6xHMTgGPHLJpx9kunYl3ZgBpUUUJ7HRpE90BNU7JJ74Jr"
secrettk <- "elOR73TOXomTlvMavThhrAv6J7mmc71JbyhPHub99HzG3"
mytoken <- 	"861271732480618496-rJgG5TrInVICmluO8iJNuakqa96wLI7"
library("twitteR")
library("httr")
setup_twitter_oauth(key, secret, mytoken, secrettk)
library("twitteR")
userTimeline("Udemy", cainfo="cacert.pem")
?searchTwitter
udemytweets = searchTwitter("#Udemy", n=1000, cainfo="cacert.pem")
key <- "22LdoMzzR7KJgp2LxWH6XDrfT"
secret <- "ZpKjG6xHMTgGPHLJpx9kunYl3ZgBpUUUJ7HRpE90BNU7JJ74Jr"
secrettk <- "elOR73TOXomTlvMavThhrAv6J7mmc71JbyhPHub99HzG3"
mytoken <- 	"861271732480618496-rJgG5TrInVICmluO8iJNuakqa96wLI7"
library("twitteR")
library("httr")
?setup_twitter_oauth
setup_twitter_oauth(key, secret, mytoken, secrettk)
setup_twitter_oauth(key, secret)
key <- "n4RBNeOKXgjF97pp93tv0vAK6"
secret <- "cazafkzwfHlacuqvBy0FAdEKGyZqN3F1jPIwpeTIDDdrMreoJV"
secrettk <- "JPUh0ovIuZLMLhOwmY4hgsiiNmZp62cNr3XJ5pYH9FuqV"
mytoken <- 	"861271732480618496-QnM6qtZ1MIYCKRlA8oqIIJwFaFJWUQU"
library("twitteR")
library("httr")
?setup_twitter_oauth
setup_twitter_oauth(key, secret, mytoken, secrettk)
udemytweets = searchTwitter("#Udemy", n=1000)
udemytweets = searchTwitter("#Udemy", n=1000)
udemytweets = searchTwitter("#Udemy", n=1000)
class(udemytweets)
length(udemytweets)
head(udemytweets)
library("tm")
install.packages("tm")
library("tm")
key <- "n4RBNeOKXgjF97pp93tv0vAK6"
secret <- "cazafkzwfHlacuqvBy0FAdEKGyZqN3F1jPIwpeTIDDdrMreoJV"
secrettk <- "JPUh0ovIuZLMLhOwmY4hgsiiNmZp62cNr3XJ5pYH9FuqV"
mytoken <- 	"861271732480618496-QnM6qtZ1MIYCKRlA8oqIIJwFaFJWUQU"
library("twitteR")
library("httr")
?setup_twitter_oauth
setup_twitter_oauth(key, secret, mytoken, secrettk)
udemytweets = searchTwitter("#Udemy", n=1000)
class(udemytweets)
length(udemytweets)
head(udemytweets)
library("tm")
udemylist <- sapply(udemytweets, function(x) x$getText()) # initiating a function
udemycorpus <- Corpus(VectorSource(udemylist)) # use the corpus function
udemycorpus <- tm_map(udemycorpus, tolower) # putting text to lower case
udemycorpus <- tm_map(udemycorpus, removePunctuation) # remove punct.
udemycorpus <- tm_map(udemycorpus,
function(x)removeWords(x,stopwords())) # remove stopwords (meaningless words)
?getTransformations
udemycorpus <- tm_map(udemycorpus, PlainTextDocument)
library("wordcloud")
